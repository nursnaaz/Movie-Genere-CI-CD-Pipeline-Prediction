{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36c85904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohamednoordeenalaudeen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16206766206766207\n",
      "F1-score: 0.5600685836094441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('movies_metadata.csv')\n",
    "\n",
    "# Extract required columns\n",
    "data = data[['overview', 'genres']]\n",
    "\n",
    "# Clean the data\n",
    "def parse(x):\n",
    "    names = []\n",
    "    x = eval(x)\n",
    "    for dictionary in x:\n",
    "        names.append(dictionary['name'])\n",
    "    return names\n",
    "\n",
    "data['target'] = data['genres'].apply(parse)\n",
    "data = data[data['target'].apply(lambda x: len(x)) > 0]\n",
    "data = data.dropna(subset=['overview'])\n",
    "\n",
    "# Text cleaning and stopword removal\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_cleaned = X.apply(self.clean_text)\n",
    "        return X_cleaned\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(\"\\'\", \"\", text)\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text = ' '.join(text.split())\n",
    "        text = text.lower()\n",
    "        text = self.remove_stopwords(text)\n",
    "        return text\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens_cleaned = [token for token in tokens if token.lower() not in self.stopwords]\n",
    "        return ' '.join(tokens_cleaned)\n",
    "\n",
    "# Split the dataset\n",
    "overview = data['overview']\n",
    "genres = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(overview, genres, test_size=0.5, random_state=42)\n",
    "\n",
    "# Apply MultiLabelBinarizer to target labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_binarized = mlb.fit_transform(y_train)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('cleaner', TextPreprocessor()),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.8, max_features=10000)),\n",
    "    ('model', OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train_binarized)\n",
    "\n",
    "\n",
    "# Save the pipeline and MultiLabelBinarizer\n",
    "pickle.dump(pipeline, open('model_pipeline.pkl', 'wb'))\n",
    "pickle.dump(mlb, open('mlb.pkl', 'wb'))\n",
    "\n",
    "\n",
    "mlb_new = pickle.load(open(\"mlb.pkl\", 'rb'))\n",
    "y_test_binarized = mlb_new.transform(y_test)\n",
    "\n",
    "\n",
    "y_pred_prob = pipeline.predict_proba(X_test)\n",
    "t = 0.3 # threshold value\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "accuracy = accuracy_score(y_test_binarized, y_pred_new)\n",
    "f1 = f1_score(y_test_binarized, y_pred_new, average='micro')  # Micro-average F1-score for multi-label classification\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
